{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6mQO_bum44AF"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QblZRbc846gx"
      },
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NKqs_Rhq48w_"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)  # 30% for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ACJMzZh04-g-"
      },
      "outputs": [],
      "source": [
        "# Linear kernel\n",
        "svm_linear = SVC(kernel='linear')\n",
        "svm_linear.fit(X_train, y_train)\n",
        "y_pred_linear = svm_linear.predict(X_test)\n",
        "\n",
        "# Polynomial kernel\n",
        "svm_poly = SVC(kernel='poly')\n",
        "svm_poly.fit(X_train, y_train)\n",
        "y_pred_poly = svm_poly.predict(X_test)\n",
        "\n",
        "# RBF kernel\n",
        "svm_rbf = SVC(kernel='rbf')\n",
        "svm_rbf.fit(X_train, y_train)\n",
        "y_pred_rbf = svm_rbf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WemIAmPK5A5o",
        "outputId": "fabcb3b6-68e8-4dea-b533-44ecaac68960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Kernel Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n",
            "\n",
            "Polynomial Kernel Accuracy: 0.9777777777777777\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.97      0.97        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n",
            "\n",
            "RBF Kernel Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Linear kernel\n",
        "print(\"Linear Kernel Accuracy:\", accuracy_score(y_test, y_pred_linear))\n",
        "print(classification_report(y_test, y_pred_linear))\n",
        "\n",
        "# Polynomial kernel\n",
        "print(\"\\nPolynomial Kernel Accuracy:\", accuracy_score(y_test, y_pred_poly))\n",
        "print(classification_report(y_test, y_pred_poly))\n",
        "\n",
        "# RBF kernel\n",
        "print(\"\\nRBF Kernel Accuracy:\", accuracy_score(y_test, y_pred_rbf))\n",
        "print(classification_report(y_test, y_pred_rbf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QDloqbDC5DBY",
        "outputId": "e0008e09-5318-45b5-d0b4-3741e370eea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "[CV 1/5] END ................C=0.1, gamma=0.001;, score=0.333 total time=   0.0s\n",
            "[CV 2/5] END ................C=0.1, gamma=0.001;, score=0.333 total time=   0.0s\n",
            "[CV 3/5] END ................C=0.1, gamma=0.001;, score=0.333 total time=   0.0s\n",
            "[CV 4/5] END ................C=0.1, gamma=0.001;, score=0.333 total time=   0.0s\n",
            "[CV 5/5] END ................C=0.1, gamma=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5] END .................C=0.1, gamma=0.01;, score=0.524 total time=   0.0s\n",
            "[CV 2/5] END .................C=0.1, gamma=0.01;, score=0.619 total time=   0.0s\n",
            "[CV 3/5] END .................C=0.1, gamma=0.01;, score=0.333 total time=   0.0s\n",
            "[CV 4/5] END .................C=0.1, gamma=0.01;, score=0.333 total time=   0.0s\n",
            "[CV 5/5] END .................C=0.1, gamma=0.01;, score=0.524 total time=   0.0s\n",
            "[CV 1/5] END ..................C=0.1, gamma=0.1;, score=1.000 total time=   0.0s\n",
            "[CV 2/5] END ..................C=0.1, gamma=0.1;, score=0.857 total time=   0.0s\n",
            "[CV 3/5] END ..................C=0.1, gamma=0.1;, score=0.810 total time=   0.0s\n",
            "[CV 4/5] END ..................C=0.1, gamma=0.1;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ..................C=0.1, gamma=0.1;, score=0.857 total time=   0.0s\n",
            "[CV 1/5] END ....................C=0.1, gamma=1;, score=1.000 total time=   0.0s\n",
            "[CV 2/5] END ....................C=0.1, gamma=1;, score=0.905 total time=   0.0s\n",
            "[CV 3/5] END ....................C=0.1, gamma=1;, score=0.905 total time=   0.0s\n",
            "[CV 4/5] END ....................C=0.1, gamma=1;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ....................C=0.1, gamma=1;, score=0.905 total time=   0.0s\n",
            "[CV 1/5] END ..................C=1, gamma=0.001;, score=0.619 total time=   0.0s\n",
            "[CV 2/5] END ..................C=1, gamma=0.001;, score=0.619 total time=   0.0s\n",
            "[CV 3/5] END ..................C=1, gamma=0.001;, score=0.333 total time=   0.0s\n",
            "[CV 4/5] END ..................C=1, gamma=0.001;, score=0.333 total time=   0.0s\n",
            "[CV 5/5] END ..................C=1, gamma=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5] END ...................C=1, gamma=0.01;, score=1.000 total time=   0.0s\n",
            "[CV 2/5] END ...................C=1, gamma=0.01;, score=0.905 total time=   0.0s\n",
            "[CV 3/5] END ...................C=1, gamma=0.01;, score=0.905 total time=   0.0s\n",
            "[CV 4/5] END ...................C=1, gamma=0.01;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ...................C=1, gamma=0.01;, score=0.857 total time=   0.0s\n",
            "[CV 1/5] END ....................C=1, gamma=0.1;, score=1.000 total time=   0.0s\n",
            "[CV 2/5] END ....................C=1, gamma=0.1;, score=0.905 total time=   0.0s\n",
            "[CV 3/5] END ....................C=1, gamma=0.1;, score=0.905 total time=   0.0s\n",
            "[CV 4/5] END ....................C=1, gamma=0.1;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ....................C=1, gamma=0.1;, score=0.952 total time=   0.0s\n",
            "[CV 1/5] END ......................C=1, gamma=1;, score=0.952 total time=   0.0s\n",
            "[CV 2/5] END ......................C=1, gamma=1;, score=0.905 total time=   0.0s\n",
            "[CV 3/5] END ......................C=1, gamma=1;, score=0.905 total time=   0.0s\n",
            "[CV 4/5] END ......................C=1, gamma=1;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ......................C=1, gamma=1;, score=0.952 total time=   0.0s\n",
            "[CV 1/5] END .................C=10, gamma=0.001;, score=1.000 total time=   0.0s\n",
            "[CV 2/5] END .................C=10, gamma=0.001;, score=0.905 total time=   0.0s\n",
            "[CV 3/5] END .................C=10, gamma=0.001;, score=0.905 total time=   0.0s\n",
            "[CV 4/5] END .................C=10, gamma=0.001;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END .................C=10, gamma=0.001;, score=0.857 total time=   0.0s\n",
            "[CV 1/5] END ..................C=10, gamma=0.01;, score=1.000 total time=   0.0s\n",
            "[CV 2/5] END ..................C=10, gamma=0.01;, score=0.905 total time=   0.0s\n",
            "[CV 3/5] END ..................C=10, gamma=0.01;, score=0.905 total time=   0.0s\n",
            "[CV 4/5] END ..................C=10, gamma=0.01;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ..................C=10, gamma=0.01;, score=0.952 total time=   0.0s\n",
            "[CV 1/5] END ...................C=10, gamma=0.1;, score=0.952 total time=   0.0s\n",
            "[CV 2/5] END ...................C=10, gamma=0.1;, score=0.952 total time=   0.0s\n",
            "[CV 3/5] END ...................C=10, gamma=0.1;, score=0.905 total time=   0.0s\n",
            "[CV 4/5] END ...................C=10, gamma=0.1;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ...................C=10, gamma=0.1;, score=0.952 total time=   0.0s\n",
            "[CV 1/5] END .....................C=10, gamma=1;, score=0.952 total time=   0.0s\n",
            "[CV 2/5] END .....................C=10, gamma=1;, score=0.905 total time=   0.0s\n",
            "[CV 3/5] END .....................C=10, gamma=1;, score=0.905 total time=   0.0s\n",
            "[CV 4/5] END .....................C=10, gamma=1;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END .....................C=10, gamma=1;, score=0.952 total time=   0.0s\n",
            "[CV 1/5] END ................C=100, gamma=0.001;, score=1.000 total time=   0.0s\n",
            "[CV 2/5] END ................C=100, gamma=0.001;, score=0.905 total time=   0.0s\n",
            "[CV 3/5] END ................C=100, gamma=0.001;, score=0.905 total time=   0.0s\n",
            "[CV 4/5] END ................C=100, gamma=0.001;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ................C=100, gamma=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 1/5] END .................C=100, gamma=0.01;, score=1.000 total time=   0.0s\n",
            "[CV 2/5] END .................C=100, gamma=0.01;, score=0.952 total time=   0.0s\n",
            "[CV 3/5] END .................C=100, gamma=0.01;, score=0.905 total time=   0.0s\n",
            "[CV 4/5] END .................C=100, gamma=0.01;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END .................C=100, gamma=0.01;, score=1.000 total time=   0.0s\n",
            "[CV 1/5] END ..................C=100, gamma=0.1;, score=0.952 total time=   0.0s\n",
            "[CV 2/5] END ..................C=100, gamma=0.1;, score=0.905 total time=   0.0s\n",
            "[CV 3/5] END ..................C=100, gamma=0.1;, score=0.905 total time=   0.0s\n",
            "[CV 4/5] END ..................C=100, gamma=0.1;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ..................C=100, gamma=0.1;, score=1.000 total time=   0.0s\n",
            "[CV 1/5] END ....................C=100, gamma=1;, score=0.952 total time=   0.0s\n",
            "[CV 2/5] END ....................C=100, gamma=1;, score=0.857 total time=   0.0s\n",
            "[CV 3/5] END ....................C=100, gamma=1;, score=0.905 total time=   0.0s\n",
            "[CV 4/5] END ....................C=100, gamma=1;, score=0.952 total time=   0.0s\n",
            "[CV 5/5] END ....................C=100, gamma=1;, score=0.905 total time=   0.0s\n",
            "Best parameters: {'C': 100, 'gamma': 0.01}\n",
            "Best score: 0.9714285714285715\n",
            "\n",
            "Grid Search Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
        "\n",
        "# Create GridSearchCV object\n",
        "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=3)\n",
        "\n",
        "# Fit the model to the training data\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Best score:\", grid.best_score_)\n",
        "\n",
        "# Evaluate the model with the best parameters\n",
        "y_pred_grid = grid.predict(X_test)\n",
        "print(\"\\nGrid Search Accuracy:\", accuracy_score(y_test, y_pred_grid))\n",
        "print(classification_report(y_test, y_pred_grid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZzdo54n-Zs6"
      },
      "source": [
        "1. Linear vs. RBF Kernel Performance\n",
        "Observation : Both linear and RBF kernels achieved 100% test accuracy , while RBF’s cross-validated accuracy was ~97.14%.\n",
        "Inference :\n",
        "The linear kernel’s performance suggests the Iris dataset is near-linearly separable , especially for Setosa (Class 0)\n",
        ".\n",
        "The RBF kernel’s marginally lower cross-validated accuracy (97.14%) indicates it may overfit to the test set’s specific split, as its test accuracy (100%) exceeds cross-validation\n",
        ".\n",
        "This aligns with\n",
        ", which states that a properly tuned RBF kernel should theoretically outperform linear, but dataset simplicity can reverse this.\n",
        "2. Polynomial Kernel Underperformance\n",
        "Observation : The poly kernel achieved ~97.8% accuracy with 2 misclassifications (1 Versicolor → Virginica and 1 Virginica → Versicolor).\n",
        "Inference :\n",
        "The default parameters (degree=3, gamma='scale') may be suboptimal for the Iris dataset’s simplicity. A lower degree (e.g., 2) or adjusted gamma could improve performance\n",
        ".\n",
        "The errors suggest overlap between Versicolor and Virginica, which linear and RBF kernels resolved perfectly due to their decision boundaries\n",
        ".\n",
        "3. Overfitting Risk in RBF Kernel\n",
        "Observation : The RBF kernel’s test accuracy (100%) exceeds its cross-validated score (~97.14%).\n",
        "Inference :\n",
        "The model likely overfitted to the test set’s specific samples, which may lack ambiguous cases between Versicolor and Virginica\n",
        ".\n",
        "This aligns with\n",
        ", which warns that kernel methods (like RBF) may overfit simpler datasets where linear models suffice.\n",
        "4. Hyperparameter Tuning Insights\n",
        "Observation : The best RBF parameters (C=100, gamma=0.01) improved cross-validated accuracy but did not resolve overfitting.\n",
        "Inference :\n",
        "Higher C (100) reduces regularization, allowing the model to fit the training data more closely, but this risks overfitting\n",
        ".\n",
        "gamma=0.01 balances the kernel’s influence, avoiding overemphasis on individual samples\n",
        ".\n",
        "5. Dataset Characteristics\n",
        "Observation : Linear and RBF kernels achieved 100% accuracy without tuning.\n",
        "Inference :\n",
        "The Iris dataset’s low dimensionality and near-linear separability (especially for Setosa) make it ideal for linear methods\n",
        ".\n",
        "This supports\n",
        ", which notes linear classifiers can match kernel methods on certain datasets (e.g., document data).\n",
        "6. Statistical Validity of Results\n",
        "Observation : The 100% test accuracy for linear/RBF kernels may be misleading.\n",
        "Inference :\n",
        "Reliance on NHST (Null Hypothesis Significance Testing) here is flawed, as the test set’s composition (e.g., excluding ambiguous samples) inflates accuracy\n",
        ".\n",
        "Cross-validated metrics (e.g., 97.14% for RBF) are more reliable for generalization\n",
        ".\n",
        "Key Takeaways\n",
        "Kernel Selection :\n",
        "Linear is sufficient for the Iris dataset due to its simplicity, but RBF is robust for non-linear datasets\n",
        ".\n",
        "Poly requires careful tuning of degree and gamma to avoid errors\n",
        ".\n",
        "Overfitting Mitigation :\n",
        "Use cross-validation to avoid overestimating performance (e.g., RBF’s 97.14% vs. 100% test accuracy)\n",
        ".\n",
        "Theoretical Alignment :\n",
        "The results confirm that linear kernels can outperform RBF on linearly separable data, contradicting\n",
        "’s assertion but aligning with the dataset’s simplicity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuSvAa60-sky"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
